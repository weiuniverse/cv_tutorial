{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_in_jupyter(img):\n",
    "    img_plt = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img_plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_matching(img1, img2, savefig=False):\n",
    "     '''\n",
    "    Detect, extract and match features between img1 and img2.\n",
    "    Using SIFT as the detector/extractor, but this is inconsequential to the user.\n",
    "\n",
    "    Returns: (pts1, pts2), where ptsN are points on image N.\n",
    "        The lists are \"aligned\", i.e. point i in pts1 matches with point i in pts2.\n",
    "\n",
    "    Usage example:\n",
    "        img1 = cv2.imread(\"image1.jpg\", 0)\n",
    "        img2 = cv2.imread(\"image2.jpg\", 0)\n",
    "        (pts1, pts2) = feature_matching(img1, img2)\n",
    "\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(img1)\n",
    "        plt.scatter(pts1[:,:,0],pts1[:,:,1], 0.5, c='r', marker='x')\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(img2)\n",
    "        plt.scatter(pts1[:,:,0],pts1[:,:,1], 0.5, c='r', marker='x')\n",
    "    '''\n",
    "    # Initiate SIFT detector\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks=50)   # or pass empty dictionary\n",
    "    flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "    matches2to1 = flann.knnMatch(des2,des1,k=2)\n",
    "\n",
    "    matchesMask_ratio = [[0,0] for i in xrange(len(matches2to1))]\n",
    "    match_dict = {}\n",
    "    for i,(m,n) in enumerate(matches2to1):\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            matchesMask_ratio[i]=[1,0]\n",
    "            match_dict[m.trainIdx] = m.queryIdx\n",
    "\n",
    "    good = []\n",
    "    recip_matches = flann.knnMatch(des1,des2,k=2)\n",
    "    matchesMask_ratio_recip = [[0,0] for i in xrange(len(recip_matches))]\n",
    "\n",
    "    for i,(m,n) in enumerate(recip_matches):\n",
    "        if m.distance < 0.7*n.distance: # ratio\n",
    "            if m.queryIdx in match_dict and match_dict[m.queryIdx] == m.trainIdx: #reciprocal\n",
    "                good.append(m)\n",
    "                matchesMask_ratio_recip[i]=[1,0]\n",
    "\n",
    "    if savefig:\n",
    "        draw_params = dict(matchColor = (0,255,0),\n",
    "                           singlePointColor = (255,0,0),\n",
    "                           matchesMask = matchesMask_ratio_recip,\n",
    "                           flags = 0)\n",
    "        img3 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,recip_matches,None,**draw_params)\n",
    "\n",
    "        plt.figure(),plt.xticks([]),plt.yticks([])\n",
    "        plt.imshow(img3,)\n",
    "        plt.savefig(\"feature_matching.png\",bbox_inches='tight')\n",
    "\n",
    "    return ([ kp1[m.queryIdx].pt for m in good ],[ kp2[m.trainIdx].pt for m in good ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cylindrical Warp\n",
    "Warp an image from cartesian coordinates (x, y) into cylindrical coordinates (theta, h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cylindricalWarpImage(img1, K, savefig=False):\n",
    "    '''\n",
    "    Warp an image from cartesian coordinates (x, y) into cylindrical coordinates (theta, h)\n",
    "    Returns: (image, mask)\n",
    "    Mask is [0,255], and has 255s wherever the cylindrical images has a valid value.\n",
    "    Masks are useful for stitching\n",
    "\n",
    "    Usage example:\n",
    "\n",
    "        im = cv2.imread(\"myimage.jpg\",0) #grayscale\n",
    "        h,w = im.shape\n",
    "        f = 700\n",
    "        K = np.array([[f, 0, w/2], [0, f, h/2], [0, 0, 1]]) # mock calibration matrix\n",
    "        imcyl = cylindricalWarpImage(im, K)\n",
    "    '''\n",
    "    \n",
    "    f = K[0,0]\n",
    "\n",
    "    im_h,im_w = img1.shape\n",
    "\n",
    "    # go inverse from cylindrical coord to the image\n",
    "    # (this way there are no gaps)\n",
    "    cyl = np.zeros_like(img1)\n",
    "    cyl_mask = np.zeros_like(img1)\n",
    "    cyl_h,cyl_w = cyl.shape\n",
    "    x_c = float(cyl_w) / 2.0\n",
    "    y_c = float(cyl_h) / 2.0\n",
    "    for x_cyl in np.arange(0,cyl_w):\n",
    "        for y_cyl in np.arange(0,cyl_h):\n",
    "            theta = (x_cyl - x_c) / f\n",
    "            h     = (y_cyl - y_c) / f\n",
    "            X = np.array([math.sin(theta), h, math.cos(theta)])\n",
    "            X = np.dot(K,X)\n",
    "            x_im = X[0] / X[2]\n",
    "            if x_im < 0 or x_im >= im_w:\n",
    "                continue\n",
    "\n",
    "            y_im = X[1] / X[2]\n",
    "            if y_im < 0 or y_im >= im_h:\n",
    "                continue\n",
    "\n",
    "            cyl[int(y_cyl),int(x_cyl)] = img1[int(y_im),int(x_im)]\n",
    "            cyl_mask[int(y_cyl),int(x_cyl)] = 255\n",
    "\n",
    "\n",
    "    if savefig:\n",
    "        plt.imshow(cyl, cmap='gray')\n",
    "        plt.savefig(\"cyl.png\",bbox_inches='tight')\n",
    "\n",
    "    return (cyl,cyl_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTransform(src, dst, method='affine'):\n",
    "    \n",
    "    '''\n",
    "    Calculate the geometric transform (only affine or homography) between two images,\n",
    "    based on feature matching and alignment with a robust estimator (RANSAC).\n",
    "\n",
    "    Returns: (M, pts1, pts2, mask)\n",
    "    Where: M    is the 3x3 transform matrix\n",
    "           pts1 are the matched feature points in image 1\n",
    "           pts2 are the matched feature points in image 2\n",
    "           mask is a binary mask over the lists of points that selects the transformation inliers\n",
    "\n",
    "    Usage example:\n",
    "        img1 = cv2.imread(\"image1.jpg\", 0)\n",
    "        img2 = cv2.imread(\"image2.jpg\", 0)\n",
    "        (M, pts1, pts2, mask) = getTransform(img1, img2)\n",
    "\n",
    "        # for example: transform img1 to img2's plane\n",
    "        # first, make some room around img2\n",
    "        img2 = cv2.copyMakeBorder(img2,200,200,500,500, cv2.BORDER_CONSTANT)\n",
    "        # then transform img1 with the 3x3 transformation matrix\n",
    "        out = cv2.warpPerspective(img1, M, (img2.shape[1],img2.shape[0]), dst=img2.copy(), borderMode=cv2.BORDER_TRANSPARENT)\n",
    "\n",
    "        plt.imshow(out, cmap='gray')\n",
    "        plt.show()\n",
    "    '''\n",
    "    pts1,pts2 = feature_matching(src,dst)\n",
    "\n",
    "    src_pts = np.float32(pts1).reshape(-1,1,2)\n",
    "    dst_pts = np.float32(pts2).reshape(-1,1,2)\n",
    "\n",
    "    if method == 'affine':\n",
    "        M, mask = cv2.estimateAffine2D(src_pts, dst_pts, cv2.RANSAC, ransacReprojThreshold=5.0)\n",
    "        M = np.append(M, [[0,0,1]], axis=0)\n",
    "\n",
    "    if method == 'homography':\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "    matchesMask = mask.ravel().tolist()\n",
    "\n",
    "    return (M, pts1, pts2, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective Warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Perspective_warping(img1, img2, img3):\n",
    "    '''\n",
    "    perspective warping\n",
    "    Warp img2 and img3 on img1\n",
    "    '''\n",
    "    # first, make some room around img1\n",
    "    img1 = cv2.copyMakeBorder(img1,200,200,500,500, cv2.BORDER_CONSTANT)\n",
    "\n",
    "    # then transform img2,3 with the 3x3 transformation matrix to img1 plane\n",
    "    (M21, pts2, pts1, mask) = getTransform(img2, img1,method='homography')\n",
    "    out = cv2.warpPerspective(img2, M21, (img1.shape[1],img1.shape[0]), dst=img1.copy(),flags = cv2.INTER_LINEAR,borderMode=cv2.BORDER_TRANSPARENT)\n",
    "\n",
    "    (M31, pts3, pts1, mask) = getTransform(img3, img1,method='homography')\n",
    "    output_image = cv2.warpPerspective(img3, M31, (img1.shape[1],img1.shape[0]), dst=out,flags = cv2.INTER_LINEAR,borderMode=cv2.BORDER_TRANSPARENT)\n",
    "\n",
    "    output_name = sys.argv[5] + \"output_homography.png\"\n",
    "    cv2.imwrite(output_name, output_image)\n",
    "\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cynlindrical Warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cylindrical_warping(img1, img2, img3):\n",
    "    '''\n",
    "    warp img1,2,3 to a Cynlinder\n",
    "    '''\n",
    "    \n",
    "    h1,w1 = img1.shape\n",
    "    f = 420\n",
    "    K1 = np.array([[f, 0, w1/2], [0, f, h1/2], [0, 0, 1]]) # mock calibration matrix\n",
    "    imcyl_1, mask1 = cylindricalWarpImage(img1, K1)\n",
    "\n",
    "    h2,w2 = img2.shape\n",
    "    f = 420\n",
    "    K2 = np.array([[f, 0, w2/2], [0, f, h2/2], [0, 0, 1]]) # mock calibration matrix\n",
    "    imcyl_2, mask2 = cylindricalWarpImage(img2, K2)\n",
    "\n",
    "    h3,w3 = img3.shape\n",
    "    f = 420\n",
    "    K3 = np.array([[f, 0, w3/2], [0, f, h3/2], [0, 0, 1]]) # mock calibration matrix\n",
    "    imcyl_3, mask3 = cylindricalWarpImage(img3, K3)\n",
    "\n",
    "    imcyl_1 = cv2.copyMakeBorder(imcyl_1,50,50,300,300, cv2.BORDER_CONSTANT)\n",
    "\n",
    "    (M21, pts2, pts1, mask) = getTransform(imcyl_2,imcyl_1,method='affine')\n",
    "    M21 = M21[:2,:]\n",
    "    bg = imcyl_1.copy()\n",
    "    bg = cv2.bitwise_and(bg,0)\n",
    "    out2 = cv2.warpAffine(imcyl_2, M21, (imcyl_1.shape[1],imcyl_1.shape[0]),dst=bg.copy(),flags = cv2.INTER_LINEAR,borderMode=cv2.BORDER_CONSTANT)\n",
    "    out_mask2 = cv2.warpAffine(mask2, M21, (imcyl_1.shape[1],imcyl_1.shape[0]),dst=bg.copy(),flags = cv2.INTER_LINEAR,borderMode=cv2.BORDER_TRANSPARENT)\n",
    "    mask_inv2 = cv2.bitwise_not(out_mask2)\n",
    "    plane = imcyl_1.copy()\n",
    "    img1_bg = cv2.bitwise_and(plane,plane,mask = mask_inv2)\n",
    "    out12 = cv2.add(img1_bg,out2)\n",
    "\n",
    "    (M31, pts3, pts1, mask) = getTransform(imcyl_3,imcyl_1,method='affine')\n",
    "    M31 = M31[:2,:]\n",
    "    out3 = cv2.warpAffine(imcyl_3, M31, (imcyl_1.shape[1],imcyl_1.shape[0]),dst=bg.copy(),flags = cv2.INTER_LINEAR,borderMode=cv2.BORDER_TRANSPARENT)\n",
    "    out_mask3 = cv2.warpAffine(mask3, M31, (imcyl_1.shape[1],imcyl_1.shape[0]),dst=bg.copy(),flags = cv2.INTER_LINEAR,borderMode=cv2.BORDER_TRANSPARENT)\n",
    "    mask_inv3 = cv2.bitwise_not(out_mask3)\n",
    "    plane12 = out12.copy()\n",
    "    img12_bg = cv2.bitwise_and(plane12,plane12,mask = mask_inv3)\n",
    "    output_image = cv2.add(img12_bg,out3)\n",
    "\n",
    "    output_name = sys.argv[5] + \"output_cylindrical.png\"\n",
    "    cv2.imwrite(output_name, output_image)\n",
    "\n",
    "    return output_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplacian warping\n",
    "Waiting..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
